{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal notebook for generating figures\n",
    "\n",
    "It is meant to be used from command line with `jupyter-nbconvert`\n",
    "\n",
    "```\n",
    "cd <results_folder>\n",
    "jupyter-nbconvert --execute --to html --output-dir . <path-to-this-notebook>\n",
    "```\n",
    "\n",
    "This will read pickle files from the current folder and generate various graphs and text reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from types import SimpleNamespace\n",
    "import itertools\n",
    "from benchmark_rio_s3.reports import unpack_stats, gen_stats_report, join_reports\n",
    "from benchmark_rio_s3.plots import plot_stats_results, plot_comparison, plot_results\n",
    "\n",
    "os.chdir(os.environ.get('PWD','.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('*__*.pickle')\n",
    "dd_all = [pickle.load(open(file, 'rb')) for file in files if not file.startswith('WRM')]\n",
    "dd_all = sorted(dd_all, key=lambda d: d.params.nthreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = [sorted(v, key=lambda d: d.t_total)[0] \n",
    "      for _, v in itertools.groupby(dd_all, lambda d: d.params.nthreads)]\n",
    "\n",
    "sts = [unpack_stats(d, ms=True) for d in dd]\n",
    "nthreads = np.array([d.params.nthreads for d in dd])\n",
    "dd_by_thread = {d.params.nthreads:d for d in dd}\n",
    "nth_to_idx = {d.params.nthreads:i for i,d in enumerate(dd) }\n",
    "\n",
    "figs = {}\n",
    "print(nthreads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling with more threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "figs['threads'] = fig\n",
    "\n",
    "best_idx = plot_stats_results(dd, fig=fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In depth stats for single threaded case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen_stats_report(dd[0]))\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "figs['single-thread-in-depth'] = fig\n",
    "\n",
    "plot_results(dd[0].stats, fig=fig);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = (gen_stats_report(dd[0], 'One Thread'),\n",
    "           gen_stats_report(dd[best_idx], 'Lowest overall latency'))\n",
    "print(join_reports(*reports))\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "figs['comparison'] = fig\n",
    "\n",
    "plot_comparison(fig, [sts[0], sts[best_idx]],\n",
    "                      nochunk=True,\n",
    "                      threshs=[400, 200, 200],\n",
    "                      alpha=0.4,\n",
    "                      names=['c1', 'c{}'.format(dd[best_idx].params.nthreads)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    pix = np.load('tiles.npz')['data']\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    figs['sample-image'] = fig\n",
    "    ax = fig.add_axes((0,0,1,1))\n",
    "    ax.imshow(pix[0], cmap='jet')\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency hiding graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hbar_plot(ax, st, n=None, height=1, **kwargs):\n",
    "    if n is None:\n",
    "        n = st.t0.shape[0]\n",
    "    \n",
    "    for i in range(n):\n",
    "        y = i + 1\n",
    "        width = st.t_total[i]\n",
    "        t0 = st.t0[i]\n",
    "        ax.barh(y, left=t0, width=width, height=height, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "figs['latency-hiding'] = fig\n",
    "axs = [fig.add_subplot(121), fig.add_subplot(122)]\n",
    "ii = (0,1, 2, best_idx)\n",
    "for i, c in zip(ii, ['C0', 'C1', 'C3', 'C2']):\n",
    "    st = sts[i]\n",
    "    for ax in axs:\n",
    "        add_hbar_plot(ax, st, n=40, \n",
    "                      color=c, \n",
    "                      alpha=0.4, \n",
    "                      linewidth=0, \n",
    "                      label='c{}'.format(dd[i].params.nthreads))\n",
    "        ax.set_xlabel('ms')\n",
    "        ax.axis( ax.axis()[:2] + (1,41))\n",
    "\n",
    "\n",
    "axs[1].axis((0,750, *ax.axis()[2:]))\n",
    "axs[1].yaxis.set_visible(False)\n",
    "axs[1].legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,6))\n",
    "figs['fps'] = fig\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "mf = np.r_[[np.median(st.fps) for st in sts]]\n",
    "\n",
    "for st in sts:\n",
    "    ax.plot(st.fps, 'k-', alpha=0.4, linewidth=0.7)\n",
    "\n",
    "for n in [1, 8, 16, 24, nthreads[best_idx], nthreads.max()]:\n",
    "    idx = nth_to_idx[n]\n",
    "    st = sts[idx]\n",
    "    ax.plot(st.fps, '-', linewidth=2, label='c{}'.format(st.nthreads))\n",
    "\n",
    "ax.set_xlabel('Files proccessed')\n",
    "ax.set_ylabel('Files per second')\n",
    "ax.axis((-3, st.t_end.shape[0]+10) + ax.axis()[2:])\n",
    "ax.legend(loc='upper left');\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_time = np.array([np.median([st.t_open for st in d._warmup.stats]) for d in dd])\n",
    "wm_max = np.ceil(warmup_time.max()*10)/10 + 0.1\n",
    "\n",
    "fig = plt.figure(figsize=(4,4))\n",
    "figs['warmup'] = fig\n",
    "ax = fig.add_subplot(111)\n",
    "ax.barh(nthreads, warmup_time*1000, height=0.5, alpha=0.7)\n",
    "ax.axis([0, wm_max*1000, 0.5, nthreads[-1]+1.5])\n",
    "ax.yaxis.set_ticks([1, 8, 16, 24, 32, nthreads[-1]])\n",
    "ax.set_xlabel('Median time to open first file (ms)')\n",
    "ax.set_ylabel('Number of threads')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p report_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaults = dict(dpi=100)\n",
    "overrides = dict(warmup=dict(dpi=200))\n",
    "\n",
    "for name, fig in figs.items():\n",
    "    for fmt in ['svg', 'png']:\n",
    "        fname = './report_images/{name}.{fmt}'.format(name=name, fmt=fmt)\n",
    "        print('Saving to: ' + fname)\n",
    "        fig.savefig(fname, **overrides.get(name, defaults))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
